## 특징 공간의 이해
* 기계학습은 데이터를 중심으로 하는 접근방식이다.
* 기계학습은 예측(Prediction)문제를 풀며, 예측에는 회귀와 분류가 있다.
  * 회귀 : 실수값을 예측하는 문제
  * 분류 : 부류를 예측하는 문제

<회귀 그래프>

* 위 그래프에서 x축은 입력 패턴에 해당하며, y축은 패턴이 가져야 할 목표값(target value)이다.
* 기계학습에서는 x축에 해당하는 패턴을 특징(feature)이라고 하며, 특징은 <b>x</b>, 목표값을 y로 표기한다.
* 특징은 대부분 2개 이상이 포함되기 때문에 특징벡터(feature vector) 형태를 띠므로 스칼라 형태인 x가 아니라 벡터 표기인 <b>x</b>를 사용한다.
* 기계학습에 주어지는 데이터는 학습집합(learning set)또는 훈련집합(training set)이라고 한다.
* 위 그림은 y = wx + b라는 직선으로 모델을 선택할 수 있는데 여기서 w와 b는 매개변수(paramete)이다.
* 기계학습은 가장 정확하게 예측할 수 있는, 즉 최적의 매개변숫값을 찾는 작업이다.
* 이처럼, 성능을 개선하면서 최적의 상태에 도달하는 작업을 학습(learning)또는 훈련(training)이라고 한다.
* 훈련집합에 없는 새로운 샘플에 대한 목표값을 예측하는 과정을 테스트(test)라고 한다.
* 최종 목표는 훈련집합애 없는 새로운 샘플에 대한 오류를 최소화하는 것이다.
* 새로운 샘플을 가지는 데이터를 테스트집합(test set)이라고 하며, 테스트 집합에 대해 높은 성능을 가지는 성질을 일반화(generalization) 능력이라고 하며, 훈련집합과 테스트집합을 합쳐 데이터 베이스라고 한다.
* 위 그림에서는 특징공간(feature space)가 1차원이지만, 2차원 이상의 특징공간을 가지는 데이터는 <b>x</b> = (x<sub>1</sub>, x<sub>2</sub>, ... , x<sub>d</sub>>)<sup>T</sup>로 표기한다.(d차원의 데이터)
* d차원의 데이터는 d+1개의 매개변수로 다음과 같이 표현한다.
* y = w<sub>1</sub>x<sub>1</sub> +  w<sub>2</sub>x<sub>2</sub> + ... + w<sub>d</sub>x<sub>d</sub> + b
* 현대의 기계학습은 좋은 특징 공간을 찾아내는 작업을 매우 중요하게 취급하는데, 최근에는 좋은 특징 공간을 자동으로 찾아낸다는 뜻에서 '표현 학습(representation learning)'이라는 용어로 자주 사용된다.
* 딥러닝은 신경망 구조에 여러 은닉층을 두고, 왼쪽 은닉층은 저급 특징을 추출하고 오른쪽으로 갈수록 고급 특징을 추출한다.
  * 저급 특징 : 모든 영상에 공통으로 나타나는 에지나 구석점 등
  * 고급 특징 : 저급 특징이 결합한 얼굴이나 바퀴 등
* 신경망 학습 알고리즘이 특징 공간 변환 공식을 자동으로 찾아내 이러한 계층적인 특징 추출 기능을 부여한다.
* 차원의 저주(curse of dimensionality) : 차원이 높아지면서 거대한 특징 공간이 형성되며, 이 때문에 발생하는 현실적인 문제

## 기계 학습의 예
* 선형 회귀(linear regression) : 선형회귀는 y = wx + b라는 직선 모델을 사용하므로 추정해야 할 매개변수는 w,b 2개이다.
* 여기서 초기 w와 b는 난수를 생성하며 이를 사용하여 최적의 w와 b를 찾으며, 이때 최적의 &theta;(w와 b)를 찾기위해 목적함수(objective function), 비용함수(cost function)을 사용한다.

<mse 이미지>

* 위 식에서 y<sub>i</sub> - y 는 오차를 나타낸다.
* 기계 학습 알고리즘은 목적함숫값이 작아지는 방향을 찾아 매개변숫값을 조정하는 일을 반복하는데, 목적함수가 0.0또는 0.0에 아주 가까운 값으로 수렴하면 그때 학습을 마친다.
* 이때 계산에는 미분을 사용한다.
* 이처럼 작은 개선을 반복하여 최적해를 찾아가는 방법을 수치적 방법(numerical method)라고 한다.
* 분석적 방법(analytical method)는 목적 함수에서 &part;J/&part;w = 0 라는 수식으로 최적의 해를 구하는 식을 유도하는데 유도한 식을 훈련집합의 샘플을 대입하여 한꺼번에 최적해를 구하는 방식이다.

## 모델 선택
* 데이터 분포에서는 기계학습이 최적해를 찾더라고 큰 오차가 생기는데, 오차가 클 수 밖에 없는 이유는 '모델의 용량이 작기'때문이며 이런 현상을 <b>과소적합</b>(underfitting)이라고 한다.
* 만약 모델의 용량이 너무 크다면 이는 주어진 데이터의 아주 작은 잡음까지 모두 수용하게 되며, 이러한 현상을 <b>오버피팅</b>(overfitting)이라고 한다.
* 기계 학습의 최종 목표는 훈련집합에 없는 새로운 샘플을 정확하게 예측하는 것이므로 과소적합이나 과잉적합 모두 바람직하지 않다.
* 주어진 데이터와 모델에서 학습을 해도 매번 큰 오차를 가지고 온다면 이는 바이어스(bias)가 크다고 한다.
* 훈련집합이 바뀌더라고 학습 결과로 얻은 곡선들이 비슷한 현상은 분산(variance)가 작다고 한다.
* 기계 학습의 목표는 낮은 바이어스와 낮은 분산을 가지는 예측기(predictor)를 만드는 것이지만, 바이어스와 분산은 하나를 낮추면 다른 것이 높아지는 트레이드 오프(trade-off)성질을 가지고 있다. 결국 바이어스의 희생을 최소한으로 낮추면서 분산을 최대로 낮추는 전략을 써야 한다.
* 좋은 모델을 알고 있다면 문제 없지만, 그렇지 않다면 모델집합의 여러 모델을 독립적으로 학습시킨 후 그중 가장 좋은 모델을 선택하야 한다, 이때 모델을 비교하는데 사용하는 별도의 데이터가 필요하며 이 데이터집합을 검증집합(validation set)이라고 한다.
* 데이터를 수집하는데는 비용이 많이 들며 대부분 데이터가 부족하다. 따라서 이러한 상황에서는 검증집합을 따로 마련하기 힘들며 교차검즘(cross-validation)을 사용한다.
  * 교차검증 : 훈련집합을 k개의 그룹으로 나누고 그중 i번째를 제외한 k-1개의 그룹을 학습에 i번째 그룹을 검증에 사용하며, 이 과정을 k번 반복하여 각 성능을 평균하여 검증 성능을 취한다.
  * 여기서 k와 n이 같다면 이를 잭나이프 기법이라고 한다.
* 부트 스트랩(boot strap) : 난수를 사용하여 데이터를 샘플링하며, 이때 대치를 허용하여 같은 샘플이 여러번 뽑힐 수 있다.
  
  ## 규제
* 일반화 능력을 향상하는 가장 확실한 방법은 데이터를 더 많이 수집하는 것이다.
* 데이터를 추가로 수집하기 어려운 상황에서는 주로 훈련집합에 있는 샘플을 변형함으로써 인위적으로 데이터를 확대하는 방법을 사용한다.
* 이때 변형하는 정도를 잘 조정하여 샘플이 다른 부류가 되지 않도록 주의해야 한다.
* 가중치 감쇠(weight decay)는 가중치를 작게 유지함으로써 일반화 능력을 향상시키는 방법이다.
  
## 기계 학습의 유형
* 지도 방식에 따른 분류
  * 지도 학습(supervised learning)
    * 데이터가 입력(특징 벡터)과 출력(목표값) 쌍으로 주어진다.
    * 입력 특징 벡터에 대해 출력이 이러해야 한다는 정보를 알려준다는 의미에서 '지도'라고 하며, 회기와 분류가 있다.
    *  회귀는 출력이 연속되는 실수로 주어지지만, 분류는 몇가지 부류로 주어진다. 
  * 비 지도 학습(unsupervised learning)
    * 입력(특징 벡터)만 주어진다.
    * 특징 벡터만 주어지고 목표가 없으므로 지도하지 않는다는 의미에서 비지도라고 불린다.
    * 군집화 : 특징 공간에서 가까이 있는 샘플을을 같은 군집으로 모으는 작업
    * 특징 공간 변환 : 특징 공간의 차원이 커지고 데이터 베이스의 크기가 커지면 사람의 직관에 의존할 수 없어 특징 공간을 볼 수있게 변환하는 작업이다.
  * 준 지도 학습(semi-supervised learning)
    * 입력에 해당하는 특징벡터를 얻는 작업보다 레이블을 부여하는 작업은 사람이 직접 해야 하므로 비용이 많이 든다.
    * 준지도 학습은 소량의 데이터에만 부류 정보를 부여한 후, 부류 정보가 있는 소량의 데이터와 부류 정보가 없는 대량의 데이터를 함께 활용하여 성능 향상을 모색한다.
  * 강화학습(reinforcement learning)
    * 샘플마다 목표값을 주어지는 지도 학습과는 달리 연속된 샘플 열에 목표값을 하나만 주어진다.
    * 따라서 샘플 열에 속하는 각각의 샘플에 목표값을 배분하는 알고리즘이 추가로 필요하다.

* 다양한 기준에 따른 유형
  * 오프라인 학습과 온라인 학습
    * 오프라인 학습
      * 데이터 베이스의 수집, 학습, 예측이라는 순차적인 절차를 따르는 작업. 즉, 수집과 학습을 오프라인으로 수행하고, 완성된 프로그램을 현장에 설치하여 예측 작업에 활용한다.
    * 온라인 학습
      * 학습에 활용할 수 있는 데이터가 인터넷을 통해 지속적으로 발생하는 점을 주목하여 추가로 발생한 데이터를 가지고 점증적으로 학습을 하여 성능을 조금씩 개선하는 학습이다.
  * 결정론적(deterministic) 학습과 스토캐스틱(stochastic) 학습
    * 결정론적 학습
      * 같은 데이터 베이스로 학습하면 항상 같은 예측기가 만들어지지만, 초기값을 난수로 생성하기 때문에 다른 예측기가 만들어진다. 만약 같은 초기값을 사용하면 같은 예측기가 만들어진다.
    * 스토캐스틱 학습
      * 학습하는 중간에 난수를 생성하므로 같은 데이터 베이스로 학습해도 다른 예측기가 만들어진다. 또한 예측 과정에서도 난수를 사용한다.
  * 분별 모델(discriminative model) 학습과 생성 모델(generative model) 학습
    * 분별 모델 학습
      * 샘플의 부류를 예측하는 일에만 관심이 있다.
      * 분별 모델은 &Rcy;(y|<b>x</b>)만 계산하므로 예측만 할 수 있다.
    * 생성 모델 학습
      * x가 발생할 확률 &Rcy;(<b>x</b>)나 부류 y에서 <b>x</b>가 발생할 확률 &Rcy;(<b>x</b>|y)를 명시적으로 계산한다. 이 확률 정보를 이용하면 새로운 샘플을 '생성'할 수 있다.
      * 베이즈 공식을 사용하면 &Rcy;(<b>x</b>)와 &Rcy;(<b>x</b>|y)정보를 &Rcy;(y|<b>x</b>)로 변환하여 예측까지 할 수 있다.
